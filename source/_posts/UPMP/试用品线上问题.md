---
categories:
  - UPMP
---
# 试用品线上问题

## 1.超量下传问题

  更新库存失败，但是JSF带走试用品结果。![img](https://i.loli.net/2021/05/07/fDTLW1J5FqCnVeK.png) 

> 问题起因：
>
> Push2Redis 每5分钟执行一次
>
> pull2Local 每10s执行一次。
>
> 维护缓存，使用缓存一致性问题会少很多。
>
> * 利用worker去推缓存的话，redis里有restcount，而数据库里没有这就导致更新库报错，超发情况。
>
>   比如运维工具拉回N单，但5min左右误差导致本地缓存里读取的是redis里的值，订单还是可以匹配到这个活动这个仓。若拉回后RestCount是0or负数，这个仓就不会去匹配试用品活动。
>
> * 正常高并发情况同样会出现这种问题、代码里本地缓存只是检验这个活动这个仓能否匹配，匹配的量还是有redis去控制。所以问题可控。
>
> 问题解决：
>
> 1. 库存拉回后，需手动强推远端缓存，避免拉回之后的5min空窗期，导致还有订单超发。
>
> 2. 目前补写出管，扣减库存。
> 3. 技改。



## 2.憋单应急预案

业务点关注以及应急方案

1. JMQ是否积压

> 方式1.憋单若出现暂时性的积压，首先关注jmq积压数topic：ts_transferAfter，若积压量一直递增且相对比较大的消息量（1w左右）
> 方式2.关注log:"[黄金流程]jmq与jsf同步，活动未匹配，并率先进入JSF处理流程数量"(后期可增加调用次数UMP)
> 判断jmq积压导致jsf下传早于消息处理。
>
> 解决方案：
>
> 1.考虑消息积压会影响试用品匹配，应急并行队列数增大至80（100）。
>
> 2.判断机器CPU性能，若机器整体CPU良好，说明是吞吐量TCP连接受限，考虑暂停消费连接数比较大的取消消息ODC_CANCEL，upmp2_Promotion_Data_New_DELETE，ODC_COMPLETE
>
> 3.若机器CPU整体飚高，后续加机器（暂无此风险）

2. JSF下传tp99飙升，甚至严重超时

> 方式1.关注UMP监控 Upmp2.UpmpService.getTesterMarketingByJSON
>
> 方式2.关注log日志
>
> 解决方案：
>
> 1.查看upmp监控点（upmp系统  Upmp.UpmpService.getPackInfo），是否优派系统拖累，考虑关停优派系统。
>
> 2.若整体监控点延时高，考虑暂停消费topic：ts_transferAfter，避免脏数据发生。（系统降级）

运维关注

1.机器性能CPU和内存

2.数据库DB CPU

3.缓存JIMDB 

   



